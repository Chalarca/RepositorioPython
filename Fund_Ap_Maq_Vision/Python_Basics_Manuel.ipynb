{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos de Python con Numpy\n",
    "\n",
    "Bienvenido a su primera tarea. Este ejercicio le ofrece una breve introducción a Python. Incluso si has usado Python antes, esto te ayudará a familiarizarte con las funciones que necesitaremos.  \n",
    "\n",
    "**Instrucciones\n",
    "- Utilizarás Python 3.\n",
    "- Evite usar bucles for y while, a menos que se le indique explícitamente que lo haga.\n",
    "- Después de codificar tu función, ejecuta la celda que está justo debajo de ella para comprobar si tu resultado es correcto.\n",
    "\n",
    "**Después de esta tarea usted:**\n",
    "- Serás capaz de utilizar iPython Notebooks\n",
    "- Serás capaz de utilizar las funciones de numpy y las operaciones matriciales/vectoriales de numpy\n",
    "- Entender el concepto de \"transmisión\"\n",
    "- Serás capaz de vectorizar código\n",
    "\n",
    "¡Empecemos!\n",
    "\n",
    "## Nota importante sobre el envío\n",
    "\n",
    "Antes de enviar tu tarea, por favor asegúrate de que no estás haciendo lo siguiente\n",
    "\n",
    "1. No ha añadido ninguna declaración _extra_ `print` en la tarea.\n",
    "2. No ha añadido ninguna celda de código _extra_ en la tarea.\n",
    "3. No ha cambiado ningún parámetro de la función.\n",
    "4. No ha utilizado ninguna variable global dentro de sus ejercicios calificados. A menos que se le indique específicamente que lo haga, por favor absténgase de hacerlo y utilice las variables locales en su lugar.\n",
    "5. No está cambiando el código de asignación donde no es necesario, como la creación de variables _extra_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice de contenidos\n",
    "- [Acerca de iPython Notebooks](#0)\n",
    "    - [Ejercicio 1](#ex-1)\n",
    "- [1 - Construir funciones básicas con numpy](#1)\n",
    "    - [1.1 - función sigmoidea, np.exp()](#1-1)\n",
    "        - [Ejercicio 2 - basic_sigmoid](#ex-2)\n",
    "        - [Ejercicio 2 - basic_sigmoid](#ex-3)\n",
    "    - [1.2 - Gradiente sigmoide](#1-2)\n",
    "        - [Ejercicio 4 - sigmoid_derivative](#ex-4)\n",
    "    - [1.3 - Reshaping arrays](#1-3)\n",
    "        - [Ejercicio 5 - image2vector](#ex-5)\n",
    "    - [1.4 - Normalización de filas](#1-4)\n",
    "        - [Ejercicio 6 - normalizar_filas](#ex-6)\n",
    "        - [Ejercicio 7 - softmax](#ex-7)\n",
    "- [2 - Vectorización](#2)\n",
    "    - [2.1 Implement the L1 and L2 loss functions](#2-1)\n",
    "        - [Ejercicio 8 - L1](#ex-8)\n",
    "        - [Ejercicio 9 - L2](#ex-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Acerca de iPython Notebooks ##\n",
    "\n",
    "Los cuadernos iPython son entornos de codificación interactivos incrustados en una página web. En esta clase utilizarás cuadernos iPython. Sólo tienes que escribir el código entre el comentario # your code here. Después de escribir tu código, puedes ejecutar la celda presionando \"SHIFT \"+\"ENTER\" o haciendo clic en \"Ejecutar Celda\" (denotado por un símbolo de play) en la barra superior del cuaderno. \n",
    "\n",
    "A menudo especificaremos \"(≈ X líneas de código)\" en los comentarios para indicarle la cantidad de código que debe escribir. Es sólo una estimación aproximada, así que no te sientas mal si tu código es más largo o más corto.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Ejercicio 1\n",
    "Establezca el test `\"Hola Mundo\"` en la celda de abajo para imprimir \"Hola Mundo\" y ejecute las dos celdas de abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53ecb05267db45908a4d1c3f727eeb1c",
     "grade": false,
     "grade_id": "cell-edef848c738402d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (≈ 1 line of code)\n",
    "#test = \n",
    "# YOUR CODE STARTS HERE\n",
    "test='Hola Mundo'\n",
    "\n",
    "# YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Hola Mundo\n"
     ]
    }
   ],
   "source": [
    "print (\"test: \" + test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "test: Hola Mundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "<b>Lo que hay que recordar</b>:\n",
    "    \n",
    "- Ejecuta tus celdas usando SHIFT+ENTER (o \"Run cell\")\n",
    "- Escribe el código en las áreas designadas usando sólo Python 3\n",
    "- No modifiques el código fuera de las áreas designadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Construcción de funciones básicas con numpy ##\n",
    "\n",
    "Numpy es el principal paquete para la computación científica en Python. Está mantenido por una gran comunidad (www.numpy.org). En este ejercicio aprenderás varias funciones clave de numpy como `np.exp`, `np.log` y `np.reshape`. Necesitarás saber cómo usar estas funciones para futuras tareas.\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - función sigmoide, np.exp() ###\n",
    "\n",
    "Antes de usar `np.exp()`, usarás `math.exp()` para implementar la función sigmoide. Entonces verás por qué `np.exp()` es preferible a `math.exp()`.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Ejercicio 2 - sigmoide básico\n",
    "Construye una función que devuelva el sigmoide de un número real x. Usa `math.exp(x)` para la función exponencial.\n",
    "\n",
    "**Recordatorio**:\n",
    "$sigmoide(x) = \\frac{1}{1+e^{-x}}$ a veces también se conoce como función logística. Es una función no lineal utilizada no sólo en el Aprendizaje Automático (Regresión Logística), sino también en el Aprendizaje Profundo.\n",
    "\n",
    "<img src=\"images/Sigmoid.png\" style=\"width:500px;height:228px;\">\n",
    "\n",
    "Para referirse a una función perteneciente a un paquete específico se puede llamar utilizando `nombre_del_paquete.función()`. Ejecute el siguiente código para ver un ejemplo con `math.exp()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cec1a2c77dcc9c6a59470e3daf70f45",
     "grade": false,
     "grade_id": "cell-7f38ddeceef22374",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from public_tests import *\n",
    "\n",
    "# GRADED FUNCTION: basic_sigmoid\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute sigmoid of x.\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    # (≈ 1 line of code)\n",
    "    # s = \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    s=1/(1+math.exp(-x))\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "150772e06208b50e91305b4ecf1421d4",
     "grade": true,
     "grade_id": "cell-6a7680d0a31b818e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_sigmoid(1) = 0.7310585786300049\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"basic_sigmoid(1) = \" + str(basic_sigmoid(1)))\n",
    "\n",
    "basic_sigmoid_test(basic_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, rara vez utilizamos la biblioteca \"math\" en el aprendizaje profundo porque las entradas de las funciones son números reales. En el aprendizaje profundo utilizamos principalmente matrices y vectores. Por eso numpy es más útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7996/2754650752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# x se convierte en un objeto de lista python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbasic_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# verás que esto da un error cuando lo ejecutes, porque x es un vector.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7996/4292231129.py\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# YOUR CODE STARTS HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;31m# YOUR CODE ENDS HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "### Una razón por la que usamos \"numpy\" en lugar de \"math\" en Deep Learning ###\n",
    "\n",
    "x = [1, 2, 3] # x se convierte en un objeto de lista python\n",
    "basic_sigmoid(x) # verás que esto da un error cuando lo ejecutes, porque x es un vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, si $ x = (x_1, x_2, ..., x_n)$ es un vector de filas entonces `np.exp(x)` aplicará la función exponencial a cada elemento de x. La salida será entonces: `np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# example of np.exp\n",
    "t_x = np.array([1, 2, 3])\n",
    "print(np.exp(t_x)) # result is (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, si x es un vector, entonces una operación de Python como $s = x + 3$ o $s = \\frac{1}{x}$ dará como resultado como un vector del mismo tamaño que x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# example of vector operation\n",
    "t_x = np.array([1, 2, 3])\n",
    "print (t_x + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre que necesites más información sobre una función de numpy, te animamos a que consultes [la documentación oficial](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html). \n",
    "\n",
    "También puedes crear una nueva celda en el cuaderno y escribir `np.exp?` (por ejemplo) para acceder rápidamente a la documentación.\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Ejercicio 3 - sigmoide\n",
    "Implementa la función sigmoide usando numpy. \n",
    "\n",
    "**Instrucciones: x puede ser un número real, un vector o una matriz. Las estructuras de datos que usamos en numpy para representar estas formas (vectores, matrices...) se llaman arrays de numpy. No necesitas saber más por ahora.\n",
    "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\\tag{1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcab43fa930612b05f46fdd1421443db",
     "grade": false,
     "grade_id": "cell-4c5ca880d9cf9642",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 1 line of code)\n",
    "    # s = \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    s=s=1/(1+np.exp(-x))\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d6c9b80614b72a798e6df324bf20051",
     "grade": true,
     "grade_id": "cell-215cfe583f712716",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(t_x) = [0.73105858 0.88079708 0.95257413]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "t_x = np.array([1, 2, 3])\n",
    "print(\"sigmoid(t_x) = \" + str(sigmoid(t_x)))\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Gradiente Sigmoide\n",
    "\n",
    "Como has visto en la clase, necesitarás calcular gradientes para optimizar las funciones de pérdida utilizando la retropropagación. Vamos a codificar tu primera función de gradiente.\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Ejercicio 4 - sigmoid_derivative\n",
    "Implementa la función sigmoid_grad() para calcular el gradiente de la función sigmoide con respecto a su entrada x. La fórmula es \n",
    "\n",
    "$$sigmoid_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$\n",
    "\n",
    "A menudo se codifica esta función en dos pasos:\n",
    "1. Set s to be the sigmoid of x. You might find your sigmoid(x) function useful.\n",
    "2. Compute $\\sigma'(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "345fa4e729d4a65fc75c7b67b571b053",
     "grade": false,
     "grade_id": "cell-3e66ce00e171b40b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid_derivative\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente (también llamado pendiente o derivada) de la función sigmoidea con respecto a su entrada x.\n",
    "    Puedes almacenar la salida de la función sigmoide en variables y luego usarla para calcular el gradiente.\n",
    "    \n",
    "  Argumentos:\n",
    "    x -- Un escalar o un array numpy\n",
    "\n",
    "    Retorno:\n",
    "    ds -- El gradiente calculado.\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 2 lines of code)\n",
    "    # s = \n",
    "    # ds = \n",
    "    # YOUR CODE STARTS HERE\n",
    "    s=s=1/(1+np.exp(-x))\n",
    "    ds=s*(1-s)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db2f9ff9a137194ea17617bb758e1897",
     "grade": true,
     "grade_id": "cell-1b027673871951a1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(t_x) = [0.19661193 0.10499359 0.04517666]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "t_x = np.array([1, 2, 3])\n",
    "print (\"sigmoid_derivative(t_x) = \" + str(sigmoid_derivative(t_x)))\n",
    "\n",
    "sigmoid_derivative_test(sigmoid_derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Reshaping  de arrays ###\n",
    "\n",
    "Dos funciones numpy comunes utilizadas en el aprendizaje profundo son [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) y [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape se utiliza para obtener la forma (dimensión) de una matriz/vector X. \n",
    "- X.reshape(...) se utiliza para cambiar la forma de X a otra dimensión. \n",
    "\n",
    "Por ejemplo, en informática, una imagen se representa por una matriz 3D de forma $(longitud, altura, profundidad = 3)$. Sin embargo, cuando se lee una imagen como entrada de un algoritmo se convierte en un vector de forma $(longitud*altura*3, 1)$. En otras palabras, se \"desenrolla\", o se da nueva forma, a la matriz 3D en un vector 1D.\n",
    "\n",
    "<img src=\"images/image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### imagen2vector\n",
    "Implementa `image2vector()` que toma una entrada de forma (longitud, altura, 3) y devuelve un vector de forma (longitud*altura*3, 1). Por ejemplo, si quieres transformar un array v de forma (a, b, c) en un vector de forma (a*b,c) debes hacer:\n",
    "``` python\n",
    "v = v.reshape((v.shape[0] * v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "```\n",
    "- Por favor, no codifiques las dimensiones de la imagen como una constante. En su lugar, busca las cantidades que necesitas con `image.shape[0]`, etc. \n",
    "- Puedes usar v = v.reshape(-1, 1). Sólo asegúrate de entender por qué funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcbf18137f7cfa2d6ca62c4cf5c9c5d",
     "grade": false,
     "grade_id": "cell-b68b7900fdd239cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION:image2vector\n",
    "\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 1 line of code)\n",
    "    # v =\n",
    "    # YOUR CODE STARTS HERE\n",
    "    v=image.reshape((image.shape[0]*image.shape[1]*image.shape[2],1))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "339250a81053c3773a053c91cc46fb41",
     "grade": true,
     "grade_id": "cell-3b78eb8b041424f7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
    "t_image = np.array([[[ 0.67826139,  0.29380381],\n",
    "                     [ 0.90714982,  0.52835647],\n",
    "                     [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "                   [[ 0.92814219,  0.96677647],\n",
    "                    [ 0.85304703,  0.52351845],\n",
    "                    [ 0.19981397,  0.27417313]],\n",
    "\n",
    "                   [[ 0.60659855,  0.00533165],\n",
    "                    [ 0.10820313,  0.49978937],\n",
    "                    [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(t_image)))\n",
    "\n",
    "image2vector_test(image2vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-4'></a>\n",
    "### 1.4 - Normalización de filas\n",
    "\n",
    "Otra técnica común que utilizamos en Machine Learning y Deep Learning es normalizar nuestros datos. A menudo conduce a un mejor rendimiento porque el descenso de gradiente converge más rápido después de la normalización. Aquí, por normalización nos referimos a cambiar x a $ \\frac{x}{| x\\|} $ (dividiendo cada vector de fila de x por su norma).\n",
    "\n",
    "Por ejemplo, si \n",
    "$$x = \\begin{bmatrix}\n",
    "        0 & 3 & 4 \\\\\n",
    "        2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}\\tag{3}$$ \n",
    "enotonces\n",
    "$$\\| x\\| = \\text{np.linalg.norm(x, axis=1, keepdims=True)} = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix}\\tag{4} $$\n",
    "y\n",
    "$$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}\\tag{5}$$ \n",
    "\n",
    "Tenga en cuenta que puede dividir matrices de diferentes tamaños y funciona bien: esto se llama emisión y lo aprenderá en la parte 5.\n",
    "\n",
    "Con `keepdims=True` el resultado se emitirá correctamente contra la x original.\n",
    "\n",
    "El eje = 1 significa que vas a obtener la norma en una fila. Si necesitas la norma en forma de columna, necesitarás poner `axis=0`. \n",
    "\n",
    "numpy.linalg.norm tiene otro parámetro `ord` en el que se especifica el tipo de normalización que se va a realizar (en el ejercicio de abajo se hará 2-norm). Para familiarizarte con los tipos de normalización puedes visitar [numpy.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)\n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Ejercicio 6 - normalizar_filas\n",
    "Implementar normalizeRows() para normalizar las filas de una matriz. Después de aplicar esta función a una matriz de entrada x, cada fila de x debe ser un vector de longitud unitaria (es decir, de longitud 1).\n",
    "\n",
    "**Nota: No intentes usar `x /= x_norm`. Para la división de matrices, numpy debe emitir la norma x, la cual no es soportada por el operante `/=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc112a436b66b6526a5fbfe1e7822ba8",
     "grade": false,
     "grade_id": "cell-5a030834cece94f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: normalize_rows\n",
    "\n",
    "def normalize_rows(x):\n",
    "    \"\"\"\n",
    "    Implementa una función que normaliza cada fila de la matriz x (para que tenga longitud unitaria).\n",
    "    \n",
    "    Argumento:\n",
    "    x -- Una matriz numpy de forma (n, m)\n",
    "    \n",
    "    Devuelve:\n",
    "    x -- La matriz numpy normalizada (por fila). Se permite modificar x.\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 2 lines of code)\n",
    "    # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    # x_norm =\n",
    "    # Divide x by its norm.\n",
    "    # x =\n",
    "    # YOUR CODE STARTS HERE\n",
    "    x_norm=np.linalg.norm(x,ord=2,axis=1,keepdims=True)\n",
    "    x=x/x_norm\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c780d41666f3144b0d68804c2df2e21",
     "grade": true,
     "grade_id": "cell-0910101c4de92095",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizeRows(x) = [[0.         0.6        0.8       ]\n",
      " [0.13736056 0.82416338 0.54944226]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 3, 4],\n",
    "              [1, 6, 4]])\n",
    "print(\"normalizeRows(x) = \" + str(normalize_rows(x)))\n",
    "\n",
    "normalizeRows_test(normalize_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**:\n",
    "En normalize_rows(), puedes intentar imprimir las formas de x_norm y x, y luego volver a ejecutar la evaluación. Descubrirá que tienen formas diferentes. Esto es normal dado que x_norm toma la norma de cada fila de x. Así que x_norm tiene el mismo número de filas pero sólo 1 columna. Entonces, ¿cómo funcionó al dividir x por x_norm? Esto se llama difusión y ¡ahora hablaremos de ello! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-7'></a>\n",
    "### Ejercicio 7 - softmax\n",
    "Implementa una función softmax usando numpy. Puedes pensar en softmax como una función de normalización utilizada cuando tu algoritmo necesita clasificar dos o más clases. Aprenderás más sobre softmax en el segundo curso de esta especialización.\n",
    "\n",
    "**Instrucciones:\n",
    "- $\\text{for } x \\in \\mathbb{R}^{1\\times n} \\text{,     }$\n",
    "\n",
    "\\begin{align*}\n",
    " softmax(x) &= softmax\\left(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}\\right) \\\\&= \\begin{bmatrix}\n",
    "    \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} \n",
    "\\end{align*}\n",
    "\n",
    "- $\\text{for a matrix } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ se asigna al elemento en el $i^{th}$ fila y $j^{th}$ columna de  $x$, por lo que tenemos: }$  \n",
    "\n",
    "\\begin{align*}\n",
    "softmax(x) &= softmax\\begin{bmatrix}\n",
    "            x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "            x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "            x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "            \\end{bmatrix} \\\\ \\\\&= \n",
    " \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} \\\\ \\\\ &= \\begin{pmatrix}\n",
    "    softmax\\text{(first row of x)}  \\\\\n",
    "    softmax\\text{(second row of x)} \\\\\n",
    "    \\vdots  \\\\\n",
    "    softmax\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "Note that later in the course, you'll see \"m\" used to represent the \"number of training examples\", and each training example is in its own column of the matrix. Also, each feature will be in its own row (each row has data for the same feature).  \n",
    "Softmax should be performed for all features of each training example, so softmax would be performed on the columns (once we switch to that representation later in this course).\n",
    "\n",
    "However, in this coding practice, we're just focusing on getting familiar with Python, so we're using the common math notation $m \\times n$  \n",
    "where $m$ is the number of rows and $n$ is the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5100054e6e6ea2c9a6343b43406cf909",
     "grade": false,
     "grade_id": "cell-f41746c0a00bd2fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: softmax\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Calcula el softmax para cada fila de la entrada x.\n",
    "\n",
    "    Su código debe funcionar para un vector de filas y también para matrices de forma (m,n).\n",
    "\n",
    "    Argumento:\n",
    "    x -- Una matriz numpy de forma (m,n)\n",
    "\n",
    "    Devuelve:\n",
    "    s -- Una matriz numpy igual al softmax de x, de forma (m,n)\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 3 líneas de código)\n",
    "    # Aplica exp() de forma elemental a x. Usa np.exp(...).\n",
    "    # x_exp = ...\n",
    "\n",
    "    # Crear un vector x_sum que sume cada fila de x_exp. Usa np.sum(..., axis = 1, keepdims = True).\n",
    "    # x_sum = ...\n",
    "    \n",
    "    # Calcula softmax(x) dividiendo x_exp por x_sum. Debería utilizar automáticamente la emisión de numpy.\n",
    "    # s = ...\n",
    "    \n",
    "    # YOUR CODE STARTS HERE\n",
    "    x_exp=np.exp(x)\n",
    "    x_sum=np.sum(x_exp,axis=1,keepdims=True)\n",
    "    s=x_exp/x_sum\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e598fb22ddfec51bbdb6d08af1076cc5",
     "grade": true,
     "grade_id": "cell-6f8e1f025948128c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "t_x = np.array([[9, 2, 5, 0, 0],\n",
    "                [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(t_x)))\n",
    "\n",
    "softmax_test(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notas\n",
    "- Si imprimes las formas de x_exp, x_sum y s arriba y vuelves a ejecutar la celda de evaluación, verás que x_sum es de forma (2,1) mientras que x_exp y s son de forma (2,5). **x_exp/x_sum** funciona gracias a la transmisión de python.\n",
    "\n",
    "¡Felicitaciones! Ahora tienes una comprensión bastante buena de numpy python y has implementado algunas funciones útiles que vas a utilizar en el aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "<b>Lo que hay que recordar:</b>\n",
    "    \n",
    "- np.exp(x) funciona para cualquier np.array x y aplica la función exponencial a cada coordenada\n",
    "- la función sigmoidea y su gradiente\n",
    "- image2vector se utiliza comúnmente en el aprendizaje profundo\n",
    "- np.reshape es ampliamente utilizado. En el futuro, verás que mantener las dimensiones de tus matrices/vectores en orden te ayudará a eliminar muchos errores. \n",
    "- numpy tiene funciones incorporadas eficientes\n",
    "- la transmisión es extremadamente útil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Vectorización\n",
    "\n",
    "\n",
    "En el aprendizaje profundo, se trabaja con conjuntos de datos muy grandes. Por lo tanto, una función no óptima desde el punto de vista computacional puede convertirse en un enorme cuello de botella en su algoritmo y puede dar lugar a un modelo que tarda siglos en ejecutarse. Para asegurarse de que su código es computacionalmente eficiente, utilizará la vectorización. Por ejemplo, intente diferenciar entre las siguientes implementaciones del producto punto/extremo/elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Computation time = 15.625ms\n",
      "outer = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      " ----- Tiempo de cálculo = 0.0ms\n",
      "elementwise multiplication = [81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
      " ----- Tiempo de cálculo = 0.0ms\n",
      "gdot = [16.17135356 24.10461648 17.06207669]\n",
      " ----- Tiempo de cálculo = 0.0ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### APLICACIÓN CLÁSICA DEL PRODUCTO PUNTO DE LOS VECTORES ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    dot += x1[i] * x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### APLICACIÓN CLÁSICA DEL PRODUCTO EXTERIOR ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1), len(x2))) # creamos una matriz len(x1)*len(x2) con sólo ceros\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i] * x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Tiempo de cálculo = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### APLICACIÓN CLÁSICA DE LOS ELEMENTOS ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i] * x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Tiempo de cálculo = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### IMPLEMENTACIÓN CLÁSICA DEL PRODUCTO PUNTO GENERAL  ###\n",
    "W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j] * x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Tiempo de cálculo = \" + str(1000 * (toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Tiempo de cálculo = 0.0ms\n",
      "outer = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      " ----- Tiempo de cálculo = 0.0ms\n",
      "elementwise multiplication = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
      " ----- Tiempo de cálculo = 0.0ms\n",
      "gdot = [16.17135356 24.10461648 17.06207669]\n",
      " ----- Tiempo de cálculo = 0.0ms\n"
     ]
    }
   ],
   "source": [
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### PRODUCTO PUNTO VECTORIAL DE VECTORES ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Tiempo de cálculo = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### PRODUCTO EXTERIOR VECTORIZADO ###\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Tiempo de cálculo = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### MULTIPLICACIÓN VECTORIAL POR ELEMENTOS ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Tiempo de cálculo = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### PRODUCTO PUNTO GENERAL VECTORIZADO ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(dot) + \"\\n ----- Tiempo de cálculo = \" + str(1000 * (toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habrá notado, la implementación vectorizada es mucho más limpia y eficiente. Para vectores/matrices más grandes, las diferencias en el tiempo de ejecución son aún mayores. \n",
    "\n",
    "**Nota** que `np.dot()` realiza una multiplicación matriz-matriz o matriz-vector. Esto es diferente de `np.multiply()` y del operador `*` (que es equivalente a `.*` en Matlab/Octave), que realiza una multiplicación elemento a elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 Implementar las funciones de pérdida L1 y L2\n",
    "\n",
    "<a name='ex-8'></a>\n",
    "### Ejercicio 8 - L1 \n",
    "Implementa la versión vectorizada en numpy de la pérdida L1. Puedes encontrar útil la función abs(x) (valor absoluto de x).\n",
    "\n",
    "**Recordatorio**:\n",
    "- La pérdida se utiliza para evaluar el rendimiento de tu modelo. Cuanto mayor sea la pérdida, más diferentes serán tus predicciones ($ \\hat{y} $) de los valores reales ($y$). En el aprendizaje profundo, se utilizan algoritmos de optimización como el Gradient Descent para entrenar su modelo y minimizar el coste.\n",
    "- La pérdida L1 se define como:\n",
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^{m-1}|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c496fe0b5fb6fe1580162305cf97387",
     "grade": false,
     "grade_id": "cell-410accbd4d9a1fc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L1\n",
    "\n",
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    yhat -- vector de tamaño m (etiquetas predichas)\n",
    "    y -- vector de tamaño m (etiquetas verdaderas)\n",
    "    \n",
    "    Devuelve:\n",
    "    loss -- el valor de la función de pérdida L1 definida anteriormente\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 1 line of code)\n",
    "    # loss = \n",
    "    # YOUR CODE STARTS HERE\n",
    "    loss = np.sum(abs(y - yhat))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7435251c8f0959006b7034fd1eb9a2d3",
     "grade": true,
     "grade_id": "cell-44ac3b50c1fba7a0",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat, y)))\n",
    "\n",
    "L1_test(L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-9'></a>\n",
    "### Exercise 9 - L2\n",
    "Implementa la versión vectorizada de numpy de la pérdida L2. Hay varias formas de implementar la pérdida L2, pero puedes encontrar útil la función np.dot(). Como recordatorio, si $x = [x_1, x_2, ..., x_n]$, entonces `np.dot(x,x)` = $\\sum_{j=0}^n x_j^{2}$. \n",
    "\n",
    "- La pérdida L2 se define como $$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d806d7037061895561c70f6abb03380e",
     "grade": false,
     "grade_id": "cell-a2624d0db4d22322",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L2\n",
    "\n",
    "def L2(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    yhat -- vector de tamaño m (etiquetas predichas)\n",
    "    y -- vector de tamaño m (etiquetas verdaderas)\n",
    "    \n",
    "    Devuelve:\n",
    "    loss -- el valor de la función de pérdida L2 definida anteriormente\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 1 line of code)\n",
    "    # loss = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    loss = np.sum(np.square(y - yhat))\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef616282fe941f332052dbb8641e9aa8",
     "grade": true,
     "grade_id": "cell-e7809ad65b5fe0ab",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "\n",
    "print(\"L2 = \" + str(L2(yhat, y)))\n",
    "\n",
    "L2_test(L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felicitaciones por haber completado esta tarea. Esperamos que este pequeño ejercicio de calentamiento te ayude en las futuras tareas, que serán más emocionantes e interesantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "<b>Lo que hay que recordar:</b>\n",
    "    \n",
    "- La vectorización es muy importante en el aprendizaje profundo. Proporciona eficiencia computacional y claridad.\n",
    "- Has revisado la pérdida L1 y L2.\n",
    "- Estás familiarizado con muchas funciones de numpy como np.sum, np.dot, np.multiply, np.maximum, etc..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
