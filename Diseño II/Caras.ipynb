{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from os import mkdir\n",
    "import psutil\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import serial\n",
    "import threading\n",
    "import imutils\n",
    "\n",
    "process = psutil.Process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registro_facial():\n",
    "    global direc\n",
    "    n=0\n",
    "    usuario_num = str(dato_numero1.get())    \n",
    "    direc =str(\"Ruta\"+usuario_num) # direccion de la carpeta donde se almacena cada usuario sengo su documento\n",
    "    mkdir(direc)  # creamos la carpeta\n",
    "    archi1=open(direc+'/datos.txt',\"w\") # creamos el archivo txt\n",
    "    archi1.write(str(dato_nombre1.get())+\"\\n\")  # guardamos el nombre y cambiamos de renglon\n",
    "    archi1.write(str(dato_apellido1.get())+\"\\n\") # guardamos apellido\n",
    "    archi1.write(str(dato_numero1.get())+\"\\n\")  # guardamos el documento estos 3 se pueden hacer en una sola linea de codigo\n",
    "\n",
    "\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    #cap = cv2.VideoCapture(\"video.mp4\")\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        min_detection_confidence=0.5) as face_detection:\n",
    "        while True:\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            height, width, _ = frame.shape\n",
    "            if ret == False:\n",
    "                break\n",
    "            #frame = imutils.resize(frame, width=720)\n",
    "            #frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)        \n",
    "            results = face_detection.process(frame_rgb)\n",
    "            if results.detections is not None:\n",
    "                n=n+1\n",
    "                for detection in results.detections:\n",
    "                    \n",
    "                    xmin = int(detection.location_data.relative_bounding_box.xmin * width)\n",
    "                    ymin = int(detection.location_data.relative_bounding_box.ymin * height)\n",
    "                    w = int(detection.location_data.relative_bounding_box.width * width)\n",
    "                    h = int(detection.location_data.relative_bounding_box.height * height)\n",
    "                    try:\n",
    "                        ajs=10\n",
    "                        ign=3\n",
    "                        cv2.rectangle(frame, (xmin-ajs, ymin-ajs-5), (xmin + w+ajs, ymin + h+ajs), (0, 255, 0), 2)\n",
    "                        #mp_drawing.draw_detection(frame, detection,mp_drawing.DrawingSpec(color=(0, 255, 255), circle_radius=2))\n",
    "                        imgp_rec=frame[ymin-ajs:ymin-ajs + h,xmin:xmin + w]\n",
    "                        imgp_rec = cv2.resize(imgp_rec, (240,240), interpolation = cv2.INTER_CUBIC)\n",
    "                        if n%ign==0:\n",
    "                            cv2.imwrite(direc+\"/img\"+str(n/ign)+\".jpg\", imgp_rec)\n",
    "                        cv2.imshow(\"Frame2\", imgp_rec)\n",
    "                    except:\n",
    "                        0\n",
    "                if (n >= 400*ign): \n",
    "                    break\n",
    "            texto = \"mira hacia la luz\"\n",
    "            cv2.putText(frame,texto, \n",
    "            (120,30),cv2.FONT_HERSHEY_TRIPLEX,\n",
    "            1,(221,0,0),1)\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            \n",
    "            k = cv2.waitKey(1) & 0xFF\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def activar(*args):\n",
    "    \n",
    "    text1 = dato_nombre1.get().lower()\n",
    "    text2 = dato_apellido1.get().lower()\n",
    "    text3 = dato_numero1.get().lower()\n",
    "    \n",
    "    if text1 != '' :\n",
    "        if text2 != '':\n",
    "            if text3 != '':\n",
    "                boton.configure(state = NORMAL)\n",
    "       \n",
    "    else : boton.configure(state = DISABLED)\n",
    "    \n",
    "#contenedor datos de usuario \n",
    "    \n",
    "global nombre1      #Globalizamos la variable para usarla en las funciones\n",
    "global dato_nombre1\n",
    "global apellido1\n",
    "global dato_apellido1\n",
    "global numero1\n",
    "global dato_numero1\n",
    "global boton\n",
    "    \n",
    "ventana = Tk()\n",
    "ventana.geometry(\"300x250\")  #Asignamos el tamaño a la ventana \n",
    "ventana.title(\"bot Industries\")  #Asignamos el titulo a la ventana\n",
    "#icono = PhotoImage(file =\"D:\\UNIVERSIDAD\\Diseño_Mecatronico_2\\Comunicacion_Serial\\log.png\") # ubicacion del icono\n",
    "#ventana.iconphoto(True, icono)  # activo el icono\n",
    "\n",
    "Label(text = \"datos de registro\",\n",
    "        bg = \"white\", \n",
    "        width = \"300\",\n",
    "        height = \"2\", \n",
    "        font = (\"Verdana\", 13)).pack()  #caracteristicas de la ventana\n",
    "\n",
    "nombre1 = StringVar()   #creo las variables asignando un tipo de dato\n",
    "apellido1 = StringVar()\n",
    "numero1 = IntVar(value= '')\n",
    "   \n",
    "# datos de formulario\n",
    "    \n",
    "Label(ventana, text = \"primer nombres * \").pack()    \n",
    "dato_nombre1 = Entry(ventana, textvariable = nombre1)\n",
    "dato_nombre1.pack()\n",
    "    \n",
    "    \n",
    "Label(ventana, text = \"primer pellidos * \").pack()\n",
    "dato_apellido1 = Entry(ventana, textvariable = apellido1)\n",
    "dato_apellido1.pack()\n",
    "   \n",
    "Label(ventana, text = \"numero de documento * \").pack()\n",
    "dato_numero1 = Entry(ventana, textvariable = numero1)\n",
    "dato_numero1.pack()\n",
    "    \n",
    "nombre1.trace_add(\"write\", activar)\n",
    "apellido1.trace_add(\"write\", activar)\n",
    "numero1.trace_add(\"write\", activar)\n",
    "    \n",
    "Label(text = \"\").pack() #Creamos el espacio entre el label y el boton\n",
    "boton = tk.Button(text = \"siguiente\", \n",
    "                height = \"2\", \n",
    "                width = \"20\", \n",
    "                command = registro_facial, \n",
    "                #font = 'bold 10',\n",
    "                state=tk.DISABLED) #caracteristicas del boton que debe tener un mejor nombre\n",
    "\n",
    "boton.pack()    \n",
    "\n",
    "ventana.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "    time.sleep(0.1)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame = cv2.flip(frame,1)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "        if results.multi_face_landmarks is not None:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, face_landmarks,mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                          mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=1))\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num='1'\n",
    "\n",
    "#ser = serial.Serial('COM3', 9600) # puesto serial\n",
    "def registro_facial():\n",
    "   \n",
    "    global direc\n",
    "    usuario_num = str(dato_numero1.get())    \n",
    "    direc =str(\"Ruta\"+usuario_num) # direccion de la carpeta donde se almacena cada usuario sengo su documento\n",
    "    mkdir(direc)  # creamos la carpeta\n",
    "    archi1=open(direc+'/datos.txt',\"w\") # creamos el archivo txt\n",
    "    archi1.write(str(dato_nombre1.get())+\"\\n\")  # guardamos el nombre y cambiamos de renglon\n",
    "    archi1.write(str(dato_apellido1.get())+\"\\n\") # guardamos apellido\n",
    "    archi1.write(str(dato_numero1.get())+\"\\n\")  # guardamos el documento estos 3 se pueden hacer en una sola linea de codigo\n",
    "\n",
    "    def hilo(i):\n",
    "        \n",
    "        n=0\n",
    "        cont = 0  \n",
    "        ventana2 = cv2.VideoCapture(0)  #Elegimos la camara con la que vamos a hacer la deteccion\n",
    "                \n",
    "        if i == 0:\n",
    "            \n",
    "            while (ventana2.isOpened()):\n",
    "                \n",
    "                ret, frame = ventana2.read() \n",
    "                \n",
    "                if n >= 5:\n",
    "                    cv2.imwrite(direc+'/img.jpg', frame)  # se guarda el cuadro en una imagen temporal\n",
    "    \n",
    "                    n=0\n",
    "                a, an, c = frame.shape\n",
    "                a = int(a/2)\n",
    "                an = int(an/2)\n",
    "                cv2.ellipse(frame, (an, a), \n",
    "                (90, 140),0, 0,\n",
    "                360, (0, 0, 255),3)   \n",
    "                \n",
    "                texto = \"mira hacia la luz\"\n",
    "                cv2.putText(frame,texto, \n",
    "                (120,30),cv2.FONT_HERSHEY_TRIPLEX,\n",
    "                1,(221,0,0),1)\n",
    "                \n",
    "                cv2.imshow('Cam',frame)\n",
    "                n=n+1\n",
    "                cont = os.listdir(direc)\n",
    "                k = cv2.waitKey(1) & 0xFF\n",
    "                if k == 27:\n",
    "                    break\n",
    "                \n",
    "                if len(cont) == 3: # envia a al arduino\n",
    "                   #ser.write(num.encode())\n",
    "                   print('a')\n",
    "                   time.sleep(1)\n",
    "                   \n",
    "                if len(cont) == 10: # envia b al arduino\n",
    "                   #ser.write(num.encode())\n",
    "                   print('b')\n",
    "                   time.sleep(1)\n",
    "                \n",
    "                if len(cont) == 20: # envia c al arduino\n",
    "                   #ser.write(num.encode())\n",
    "                   print('c')\n",
    "                   time.sleep(1)\n",
    "                \n",
    "                if len(cont) == 30: # envia d al arduino\n",
    "                   #ser.write(num.encode())\n",
    "                   print('d')\n",
    "                   time.sleep(1)\n",
    "                   \n",
    "                if len(cont) >= 40: # cierra la camara cuando se cumpla el nuemro de archivos\n",
    "                   print('fin')\n",
    "                   time.sleep(1)\n",
    "                   #ser.write(num.encode())\n",
    "                   ventana2.release()   \n",
    "                   cv2.destroyAllWindows()\n",
    "                   break\n",
    "               \n",
    "       \n",
    "        if i == 1:\n",
    "            \n",
    "            while(len(os.listdir(direc))<=1):# no permite que incie el segundo hila hasta que tenaga la imagen temporal\n",
    "                time.sleep(1) \n",
    "                \n",
    "            while (True):  \n",
    "                \n",
    "                img = direc+'/img.jpg' # direcion de la imagen\n",
    "                imgp = pyplot.imread(img)  # leemos la imagen en formato pyplot\n",
    "                cara = MTCNN().detect_faces(imgp) # detectamos la cara\n",
    "                x1, y1, x2, y2 = cara[0]['box'] # obtenemos los puntos de referencia para el cuadro de la cara\n",
    "                if len(cara) == 1 : # aseguramos que en el cuadro solo se ve una cara\n",
    "                    \n",
    "                    if x1 >= 200 and x1 <= 300 and y1 >= 100 and y1 <= 200:  \n",
    "                        if x2 >= 100 and x2 <= 140 and y2 >= 100 and y2 <= 200:\n",
    "                            imgp = cv2.cvtColor(imgp, cv2.COLOR_BGR2RGB)# cambio el espacio de color\n",
    "                            x3,y3 = x1+x2, y1+y2\n",
    "                            pyplot.subplot(1, len(cara), 1)\n",
    "                            pyplot.axis('off')\n",
    "                            imgp_rec = imgp[y1-15:y3+15, x1-15:x3+15]             \n",
    "                                  \n",
    "                            try:\n",
    "                                imgp_rec = cv2.resize(imgp_rec, (240,240), interpolation = cv2.INTER_CUBIC) # guardamos la imagen con un tamaño de 255 x 255 pixeles   \n",
    "                            except cv2.error as e:\n",
    "                                print(\"Se produjo un error al redimensionar la imagen:\", str(e))\n",
    "                                imgp_rec = np.zeros((240, 240, 3), np.uint8)\n",
    "                            #cont = os.listdir(direc)\n",
    "                            cv2.imwrite(direc+\"/img\"+str(n)+\".jpg\", imgp_rec)\n",
    "                            n = n + 1 \n",
    "                            #print(direc)\n",
    "                           # print(\"/img\"+str(n)+\".jpg\")\n",
    "                            \n",
    "                                \n",
    "                if (n >= 502): \n",
    "                    break  \n",
    "        ventana2.release()\n",
    "        cv2.destroyAllWindows()                 \n",
    "    \n",
    "    simplethread=[] \n",
    "    for i in range(2):#iniciamos los hilos\n",
    "        \n",
    "        simplethread.append(threading.Thread(target=hilo, args=[i])) \n",
    "        simplethread[-1].start() \n",
    "\n",
    "    for i in range(2):     \n",
    "        simplethread[i].join() # esperamos que acabe el hilo num i\n",
    "    \n",
    "    dato_nombre1.delete(0, END)  \n",
    "    dato_apellido1.delete(0, END)\n",
    "    dato_numero1.delete(0, END)\n",
    "    \n",
    "def activar(*args):\n",
    "    \n",
    "    text1 = dato_nombre1.get().lower()\n",
    "    text2 = dato_apellido1.get().lower()\n",
    "    text3 = dato_numero1.get().lower()\n",
    "    \n",
    "    if text1 != '' :\n",
    "        if text2 != '':\n",
    "            if text3 != '':\n",
    "                boton.configure(state = NORMAL)\n",
    "       \n",
    "    else : boton.configure(state = DISABLED)\n",
    "    \n",
    "#contenedor datos de usuario \n",
    "    \n",
    "global nombre1      #Globalizamos la variable para usarla en las funciones\n",
    "global dato_nombre1\n",
    "global apellido1\n",
    "global dato_apellido1\n",
    "global numero1\n",
    "global dato_numero1\n",
    "global boton\n",
    "    \n",
    "ventana = Tk()\n",
    "ventana.geometry(\"300x250\")  #Asignamos el tamaño a la ventana \n",
    "ventana.title(\"bot Industries\")  #Asignamos el titulo a la ventana\n",
    "#icono = PhotoImage(file =\"D:\\UNIVERSIDAD\\Diseño_Mecatronico_2\\Comunicacion_Serial\\log.png\") # ubicacion del icono\n",
    "#ventana.iconphoto(True, icono)  # activo el icono\n",
    "\n",
    "Label(text = \"datos de registro\",\n",
    "        bg = \"white\", \n",
    "        width = \"300\",\n",
    "        height = \"2\", \n",
    "        font = (\"Verdana\", 13)).pack()  #caracteristicas de la ventana\n",
    "\n",
    "nombre1 = StringVar()   #creo las variables asignando un tipo de dato\n",
    "apellido1 = StringVar()\n",
    "numero1 = IntVar(value= '')\n",
    "   \n",
    "# datos de formulario\n",
    "    \n",
    "Label(ventana, text = \"primer nombre * \").pack()    \n",
    "dato_nombre1 = Entry(ventana, textvariable = nombre1)\n",
    "dato_nombre1.pack()\n",
    "    \n",
    "    \n",
    "Label(ventana, text = \"primer apellido * \").pack()\n",
    "dato_apellido1 = Entry(ventana, textvariable = apellido1)\n",
    "dato_apellido1.pack()\n",
    "   \n",
    "Label(ventana, text = \"numero de documento * \").pack()\n",
    "dato_numero1 = Entry(ventana, textvariable = numero1)\n",
    "dato_numero1.pack()\n",
    "    \n",
    "nombre1.trace_add(\"write\", activar)\n",
    "apellido1.trace_add(\"write\", activar)\n",
    "numero1.trace_add(\"write\", activar)\n",
    "    \n",
    "Label(text = \"\").pack() #Creamos el espacio entre el label y el boton\n",
    "boton = tk.Button(text = \"siguiente\", \n",
    "                height = \"2\", \n",
    "                width = \"20\", \n",
    "                command = registro_facial, \n",
    "                #font = 'bold 10',\n",
    "                state=tk.DISABLED) #caracteristicas del boton que debe tener un mejor nombre\n",
    "\n",
    "boton.pack()    \n",
    "\n",
    "ventana.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'image_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/3954539748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mreg_rostro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/3954539748.py\u001b[0m in \u001b[0;36mreg_rostro\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;31m# initializing MTCNN and InceptionResnetV1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmtcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_face_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# keep_all=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInceptionResnetV1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vggface2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'image_size'"
     ]
    }
   ],
   "source": [
    "def draw(event, x, y, flags, param): # Se declara la funcion\n",
    "    global ix, iy, drawing, mode, xf, yf  # Defino unas variables globales\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Se pregunta si se ha presionado el mouse\n",
    "        ix, iy = x, y  # Almacenamos la poscion incial en las variales\n",
    "        print(ix,iy)\n",
    "\n",
    "def reg_rostro():\n",
    "            # initializing MTCNN and InceptionResnetV1 \n",
    "    #mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False\n",
    "    mtcnn = MTCNN(image_size=240, margin=5, keep_all=False, min_face_size=40) # keep_all=True\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval() \n",
    "\n",
    "    # Using webcam recognize face\n",
    "\n",
    "    # loading data.pt file\n",
    "    load_data = torch.load('D:\\Proyectos Visual Studio\\Python-Jupyther\\Diseño II\\Bot-Industries\\Repositorio_Principal\\data.pt') \n",
    "    embedding_list = load_data[0] \n",
    "    name_list = load_data[1] \n",
    "\n",
    "    #----------------------Inicializacion de parametros----------------------------\n",
    "    # person = str(input(\"Ingrese nombre de la persona: \"))\n",
    "    # personName = '/' + person\n",
    "    cam = cv2.VideoCapture(\"D:\\Proyectos Visual Studio\\Python-Jupyther\\Diseño II\\VID_20230503_114633.mp4\") \n",
    "    # cam=cv2.VideoCapture(\"D:/UNIVERSIDAD/diseño_mecatronico2/Faces_Recognition_project/training/porteria7.mp4\") \n",
    "    #cam = cv2.VideoCapture('D:/UNIVERSIDAD/Diseño_mecatronico2/Faces_Recognition_project/training/mateo.mp4')\n",
    "    count = 0\n",
    "    cpu_array = []\n",
    "    memory_array = []\n",
    "    elapsed_time_array = []\n",
    "    c = 0\n",
    "    # dataPath = 'D:/UNIVERSIDAD/diseño_mecatronico2/Bot-Industries/Repositorio_Principal/image_data'\n",
    "    # personPath = dataPath + personName\n",
    "\n",
    "    # if not os.path.exists(personPath):\n",
    "    #     print('Creating folder:', personPath)\n",
    "    #     os.makedirs(personPath)\n",
    "\n",
    "    #--------------------Face Detection-------------------------------------------------------------\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cam.read()\n",
    "        frame = cv2.resize(frame,[1920, 1080])\n",
    "        frame=frame[300:700,368:1400]\n",
    "        cv2.rectangle(frame,(165,0),(400,400),(0,255,0),5)\n",
    "        cv2.rectangle(frame,(400,0),(650,400),(0,255,0),5)\n",
    "        cv2.rectangle(frame,(650,0),(920,400),(0,255,0),5)\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"fail to grab frame, try again\")\n",
    "            break\n",
    "            \n",
    "        img = Image.fromarray(frame)\n",
    "        img_cropped_list, prob_list = mtcnn(img, return_prob=True) \n",
    "\n",
    "        if img_cropped_list is not None:\n",
    "            boxes, _ = mtcnn.detect(img)\n",
    "                    \n",
    "            for i, prob in enumerate(prob_list):\n",
    "                if prob>0.90:\n",
    "                    emb = resnet(img_cropped_list[i].unsqueeze(0)).detach() \n",
    "                    \n",
    "                    dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "                    \n",
    "                    for idx, emb_db in enumerate(embedding_list):\n",
    "                        dist = torch.dist(emb, emb_db).item()\n",
    "                        dist_list.append(dist)\n",
    "\n",
    "                    min_dist = min(dist_list) # get minumum dist value\n",
    "                    min_dist_idx = dist_list.index(min_dist) # get minumum dist index\n",
    "                    name = name_list[min_dist_idx] # get name corrosponding to minimum dist\n",
    "                    \n",
    "                    box = boxes[i] \n",
    "                    \n",
    "                    original_frame = frame.copy() # storing copy of frame before drawing on it\n",
    "                    \n",
    "                    if min_dist<0.90:\n",
    "                        frame = cv2.putText(frame, name+' '+str(min_dist), (int(box[0]), int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),1, cv2.LINE_AA)           \n",
    "                        # os.chdir(personPath)\n",
    "                        # image_path = os.path.join(personPath, f\"face_{c}.png\")\n",
    "                        face_img = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                        if face_img is not None:\n",
    "                            face_img = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                            #aux = cv2.resize(face_img,(255,255),interpolation=cv2.INTER_CUBIC)\n",
    "                            #cv2.imwrite(f\"face_{c}.png\", aux)         \n",
    "                            frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (0,255,0), 2)\n",
    "                            c += 1   \n",
    "                            cv2.rectangle(frame,(165,0),(400,400),(0,255,0),5)\n",
    "                            cv2.rectangle(frame,(400,0),(650,400),(0,255,0),5)\n",
    "                            cv2.rectangle(frame,(650,0),(920,400),(0,255,0),5)\n",
    "\n",
    "                            if int(box[1]) >165 and int(box[1])>0 and int(box[2])<400 and int(box[3])<400:\n",
    "                                print(\"Primer Toriquete\")\n",
    "                            if int(box[1]) >400 and int(box[1])>0 and int(box[2])<650 and int(box[3])<400:\n",
    "                                print(\"Segundo Toriquete\")\n",
    "                            if int(box[1]) >650 and int(box[1])>0 and int(box[2])<920 and int(box[3])<400:\n",
    "                                print(\"Segundo Toriquete\")\n",
    "                    else:\n",
    "                        frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (0,0,255), 2)\n",
    "                    \n",
    "        cv2.imshow(\"IMG\", frame)\n",
    "        cv2.namedWindow('IMG')\n",
    "        cv2.setMouseCallback('IMG', draw)    \n",
    "        \n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256==27 or c >= 500: # ESC\n",
    "            print('Esc pressed, closing...')\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "reg_rostro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'image_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/3322109262.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mreg_rostro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/3322109262.py\u001b[0m in \u001b[0;36mreg_rostro\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# initializing MTCNN and InceptionResnetV1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmtcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_face_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# keep_all=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInceptionResnetV1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vggface2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'image_size'"
     ]
    }
   ],
   "source": [
    "# abre camara y guarda datos del reconocimiento facial\n",
    "\n",
    "\n",
    "    #Detectamos el rostro y exportamos los pixeles\n",
    "def draw(event, x, y, flags, param): # Se declara la funcion\n",
    "    global ix, iy, drawing, mode, xf, yf  # Defino unas variables globales\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Se pregunta si se ha presionado el mouse\n",
    "        ix, iy = x, y  # Almacenamos la poscion incial en las variales\n",
    "        print(ix,iy)\n",
    "\n",
    "def reg_rostro():\n",
    "            # initializing MTCNN and InceptionResnetV1 \n",
    "    #mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False\n",
    "    mtcnn = MTCNN(image_size=240, margin=5, keep_all=True, min_face_size=40) # keep_all=True\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval() \n",
    "\n",
    "    # Using webcam recognize face\n",
    "\n",
    "    # loading data.pt file\n",
    "    load_data = torch.load('D:\\Proyectos Visual Studio\\Python-Jupyther\\Diseño II\\Bot-Industries\\Repositorio_Principal\\data.pt') \n",
    "    embedding_list = load_data[0] \n",
    "    name_list = load_data[1] \n",
    "\n",
    "    #----------------------Inicializacion de parametros----------------------------\n",
    "    person = str(input(\"Ingrese nombre de la persona: \"))\n",
    "    personName = '/' + person\n",
    "    #cam = cv2.VideoCapture(0) \n",
    "    cam=cv2.VideoCapture(\"D:\\Proyectos Visual Studio\\Python-Jupyther\\Diseño II\\VID_20230503_114633.mp4\") \n",
    "    #cam = cv2.VideoCapture('D:/UNIVERSIDAD/Diseño_mecatronico2/Faces_Recognition_project/training/mateo.mp4')\n",
    "    count = 0\n",
    "    cpu_array = []\n",
    "    memory_array = []\n",
    "    elapsed_time_array = []\n",
    "    c = 0\n",
    "    dataPath = 'D:\\Proyectos Visual Studio\\Python-Jupyther\\Diseño II\\Image_data'\n",
    "    personPath = dataPath + personName\n",
    "\n",
    "    if not os.path.exists(personPath):\n",
    "        print('Creating folder:', personPath)\n",
    "        os.makedirs(personPath)\n",
    "\n",
    "    #--------------------Face Detection-------------------------------------------------------------\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cam.read()\n",
    "        frame=frame[300:700,368:1400]\n",
    "        cv2.rectangle(frame,(165,0),(400,400),(0,255,0),5)\n",
    "        cv2.rectangle(frame,(400,0),(650,400),(0,255,0),5)\n",
    "        cv2.rectangle(frame,(650,0),(920,400),(0,255,0),5)\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"fail to grab frame, try again\")\n",
    "            break\n",
    "            \n",
    "        img = Image.fromarray(frame)\n",
    "        img_cropped_list, prob_list = mtcnn(img, return_prob=True) \n",
    "\n",
    "        if img_cropped_list is not None:\n",
    "            boxes, _ = mtcnn.detect(img)\n",
    "                    \n",
    "            for i, prob in enumerate(prob_list):\n",
    "                if prob>0.90:\n",
    "                    emb = resnet(img_cropped_list[i].unsqueeze(0)).detach() \n",
    "                    \n",
    "                    dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "                    \n",
    "                    for idx, emb_db in enumerate(embedding_list):\n",
    "                        dist = torch.dist(emb, emb_db).item()\n",
    "                        dist_list.append(dist)\n",
    "\n",
    "                    min_dist = min(dist_list) # get minumum dist value\n",
    "                    min_dist_idx = dist_list.index(min_dist) # get minumum dist index\n",
    "                    name = name_list[min_dist_idx] # get name corrosponding to minimum dist\n",
    "                    \n",
    "                    box = boxes[i] \n",
    "                    \n",
    "                    original_frame = frame.copy() # storing copy of frame before drawing on it\n",
    "                    \n",
    "                    if min_dist<0.90:\n",
    "                        frame = cv2.putText(frame, name+' '+str(min_dist), (int(box[0]), int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),1, cv2.LINE_AA)           \n",
    "                        os.chdir(personPath)\n",
    "                        image_path = os.path.join(personPath, f\"face_{c}.png\")\n",
    "                        face_img = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                        if face_img is not None:\n",
    "                            face_img = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                            #aux = cv2.resize(face_img,(255,255),interpolation=cv2.INTER_CUBIC)\n",
    "                            #cv2.imwrite(f\"face_{c}.png\", aux)         \n",
    "                            frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (0,255,0), 2)\n",
    "                            c += 1   \n",
    "\n",
    "                            if int(box[0]) >165 and int(box[2])<400:\n",
    "                                print(\"Primer Toriquete\")\n",
    "                            if int(box[0]) >400 and int(box[2])<650:\n",
    "                                print(\"Segundo Toriquete\")\n",
    "                            if int(box[0]) >650 and int(box[2])<920 :\n",
    "                                print(\"Tercer Toriquete\")\n",
    "                    else:\n",
    "                        frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (0,0,255), 2)\n",
    "                    \n",
    "        cv2.imshow(\"IMG\", frame)\n",
    "        cv2.namedWindow('IMG')\n",
    "        cv2.setMouseCallback('IMG', draw)    \n",
    "        \n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256==27 or c >= 500: # ESC\n",
    "            print('Esc pressed, closing...')\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "reg_rostro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing MTCNN and InceptionResnetV1 \n",
    "mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False\n",
    "mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) # keep_all=True\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval() \n",
    "\n",
    "# Using webcam recognize face\n",
    "\n",
    "# loading data.pt file\n",
    "load_data = torch.load('Facenet_pythorch/data.pt') \n",
    "embedding_list = load_data[0] \n",
    "name_list = load_data[1] \n",
    "\n",
    "#----------------------Inicializacion de parametros----------------------------\n",
    "person = str(input(\"Ingrese nombre de la persona: \"))\n",
    "personName = '/' + person\n",
    "cam = cv2.VideoCapture(0) \n",
    "#cam = cv2.VideoCapture('D:/UNIVERSIDAD/Diseño_mecatronico2/Faces_Recognition_project/training/mateo.mp4')\n",
    "count = 0\n",
    "cpu_array = []\n",
    "memory_array = []\n",
    "elapsed_time_array = []\n",
    "c = 0\n",
    "dataPath = 'D:/UNIVERSIDAD/Diseño_mecatronico2/Faces_Recognition_project/image_data'\n",
    "personPath = dataPath + personName\n",
    "\n",
    "if not os.path.exists(personPath):\n",
    "    print('Creating folder:', personPath)\n",
    "    os.makedirs(personPath)\n",
    "\n",
    "#--------------------Face Detection-------------------------------------------------------------\n",
    "while True:\n",
    "    # Guardamos el tiempo actual antes de ejecutar el bloque de código\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"fail to grab frame, try again\")\n",
    "        break\n",
    "        \n",
    "    img = Image.fromarray(frame)\n",
    "    img_cropped_list, prob_list = mtcnn(img, return_prob=True) \n",
    "\n",
    "    if img_cropped_list is not None:\n",
    "        boxes, _ = mtcnn.detect(img)\n",
    "                \n",
    "        for i, prob in enumerate(prob_list):\n",
    "            if prob>0.90:\n",
    "                emb = resnet(img_cropped_list[i].unsqueeze(0)).detach() \n",
    "                \n",
    "                dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "                \n",
    "                for idx, emb_db in enumerate(embedding_list):\n",
    "                    dist = torch.dist(emb, emb_db).item()\n",
    "                    dist_list.append(dist)\n",
    "\n",
    "                min_dist = min(dist_list) # get minumum dist value\n",
    "                min_dist_idx = dist_list.index(min_dist) # get minumum dist index\n",
    "                name = name_list[min_dist_idx] # get name corrosponding to minimum dist\n",
    "                \n",
    "                box = boxes[i] \n",
    "                \n",
    "                original_frame = frame.copy() # storing copy of frame before drawing on it\n",
    "                \n",
    "                #if min_dist<0.90:\n",
    "                #frame = cv2.putText(frame, name+' '+str(min_dist), (int(box[0]), int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),1, cv2.LINE_AA)           \n",
    "                os.chdir(personPath)\n",
    "                image_path = os.path.join(personPath, f\"face_{c}.png\")\n",
    "                face_img = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                if face_img is not None:\n",
    "                    face_img = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                    aux = cv2.resize(face_img,(255,255),interpolation=cv2.INTER_CUBIC)\n",
    "                    cv2.imwrite(f\"face_{c}.png\", aux)         \n",
    "                    frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (0,255,0), 2)\n",
    "                    c += 1   \n",
    "\n",
    "                frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (0,0,255), 2)\n",
    "                \n",
    "    cv2.imshow(\"IMG\", frame)\n",
    "        \n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256==27 or c >= 20: # ESC\n",
    "        print('Esc pressed, closing...')\n",
    "        break\n",
    "        \n",
    "    elif k%256==32: # space to save image\n",
    "        print('Enter your name :')\n",
    "        name = input()\n",
    "        \n",
    "        # create directory if not exists\n",
    "        if not os.path.exists('photos/'+name):\n",
    "            os.mkdir('photos/'+name)\n",
    "            \n",
    "        img_name = \"photos/{}/{}.jpg\".format(name, int(time.time()))\n",
    "        cv2.imwrite(img_name, original_frame)\n",
    "        print(\" saved: {}\".format(img_name))\n",
    "    elif count >= 500:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#--------------------Training-------------------------------------------------------\n",
    "os.chdir(\"D:/UNIVERSIDAD/Diseño_mecatronico2/Facenet_pythorch\")\n",
    "opc = int(input(\"Ingrese 1 para entrenar o 2 para salir: \"))\n",
    "if opc == 1:\n",
    "    dataset = datasets.ImageFolder('D:/UNIVERSIDAD/Diseño_mecatronico2/Faces_Recognition_project/image_data') # photos folder path \n",
    "    idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n",
    "\n",
    "    def collate_fn(x):\n",
    "        return x[0]\n",
    "\n",
    "    loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "\n",
    "    name_list = [] # list of names corrospoing to cropped photos\n",
    "    embedding_list = [] # list of embeding matrix after conversion from cropped faces to embedding matrix using resnet\n",
    "\n",
    "    for img, idx in loader:\n",
    "        face, prob = mtcnn0(img, return_prob=True) \n",
    "        if face is not None and prob>0.92:\n",
    "            emb = resnet(face.unsqueeze(0)) \n",
    "            embedding_list.append(emb.detach()) \n",
    "            name_list.append(idx_to_class[idx])        \n",
    "\n",
    "    # save data\n",
    "    data = [embedding_list, name_list] \n",
    "    torch.save(data, 'data.pt') # saving data.pt file\"\"\"\n",
    "    print(\"Modelo entrenado con exito\")\n",
    "\n",
    "else:\n",
    "    print(\"Imagenes extraidas con exito\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
